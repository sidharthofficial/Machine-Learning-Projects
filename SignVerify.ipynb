{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1OEXKV1iR7RszCKr7SOrJz41f_OzUJNOC",
      "authorship_tag": "ABX9TyM2gH282wq/R/Fj8Hy1ssRE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidharthofficial/Machine-Learning-Projects/blob/master/SignVerify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs_97m7knz8x",
        "outputId": "73e53d6d-47a2-4c38-df61-8406cd7fd0ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print('GPU', 'available Yes!' if tf.config.list_physical_devices('GPU') else 'not available')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNb9V3liq3HN",
        "outputId": "88249d4e-0af6-47a9-b11a-9199f81f4248"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available Yes!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'drive/My Drive/SignVerification/'"
      ],
      "metadata": {
        "id": "fx_8irJLq6Ii"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#img = plt.imread('BHSig260-Hindi/1/H-S-1-F-01.tif')\n",
        "#plt.imshow(img)"
      ],
      "metadata": {
        "id": "Lcv8Gzwis3mX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.cm as cm\n",
        "from scipy import ndimage\n",
        "from skimage.measure import regionprops\n",
        "from skimage import io\n",
        "from skimage.filters import threshold_otsu   # For finding the threshold for grayscale to binary conversion\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from time import time\n",
        "import keras"
      ],
      "metadata": {
        "id": "ZMfoZhyzmqyI"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genuine_image_paths = 'drive/My Drive/SignAIChallenge/real/'\n",
        "forged_image_paths = 'drive/My Drive/SignAIChallenge/forged/'"
      ],
      "metadata": {
        "id": "4yW90Xnjm0mC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing the image"
      ],
      "metadata": {
        "id": "et5IZ2W9nvcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert rgb to grayscale\n",
        "def rgbgrey(img):\n",
        "    # Converts rgb to grayscale\n",
        "    greyimg = np.zeros((img.shape[0], img.shape[1]))\n",
        "    for row in range(len(img)):\n",
        "        for col in range(len(img[row])):\n",
        "            greyimg[row][col] = np.average(img[row][col])\n",
        "    return greyimg"
      ],
      "metadata": {
        "id": "GNTGVBFjn7eE"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert grayscale to binary, gaussian blur and thresholding\n",
        "def greybin(img):\n",
        "    blur_radius = 0.8\n",
        "    img = ndimage.gaussian_filter(img, blur_radius)  # to remove small components or noise\n",
        "    thres = threshold_otsu(img)\n",
        "    binimg = img > thres\n",
        "    binimg = np.logical_not(binimg)\n",
        "    return binimg"
      ],
      "metadata": {
        "id": "ctH6ZWxYoNEU"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function of preprocesing using the above 2 functions\n",
        "def preproc(path, img=None, display=True):\n",
        "    if img is None:\n",
        "        img = mpimg.imread(path)\n",
        "    if display:\n",
        "        plt.imshow(img)\n",
        "        plt.show()\n",
        "    grey = rgbgrey(img) #rgb to grey\n",
        "    if display:\n",
        "        plt.imshow(grey, cmap = matplotlib.cm.Greys_r)\n",
        "        plt.show()\n",
        "    binimg = greybin(grey) #grey to binary\n",
        "    if display:\n",
        "        plt.imshow(binimg, cmap = matplotlib.cm.Greys_r)\n",
        "        plt.show()\n",
        "    r, c = np.where(binimg==1)\n",
        "    # Now we will make a bounding box with the boundary as the position of pixels on extreme.\n",
        "    # Thus we will get a cropped image with only the signature part.\n",
        "    signimg = binimg[r.min(): r.max(), c.min(): c.max()]\n",
        "    if display:\n",
        "        plt.imshow(signimg, cmap = matplotlib.cm.Greys_r)\n",
        "        plt.show()\n",
        "    return signimg"
      ],
      "metadata": {
        "id": "qOQzVpkWojbp"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction"
      ],
      "metadata": {
        "id": "zPvuZoc1o9ZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function for Ratio\n",
        "def Ratio(img):\n",
        "    a = 0\n",
        "    for row in range(len(img)):\n",
        "        for col in range(len(img[0])):\n",
        "            if img[row][col]==True:\n",
        "                a = a+1\n",
        "    total = img.shape[0] * img.shape[1]\n",
        "    return a/total"
      ],
      "metadata": {
        "id": "7fH-6CdGotEv"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for Centroid\n",
        "def Centroid(img):\n",
        "    numOfWhites = 0\n",
        "    a = np.array([0,0])\n",
        "    for row in range(len(img)):\n",
        "        for col in range(len(img[0])):\n",
        "            if img[row][col]==True:\n",
        "                b = np.array([row,col])\n",
        "                a = np.add(a,b)\n",
        "                numOfWhites += 1\n",
        "    rowcols = np.array([img.shape[0], img.shape[1]])\n",
        "    centroid = a/numOfWhites\n",
        "    centroid = centroid/rowcols\n",
        "    return centroid[0], centroid[1]"
      ],
      "metadata": {
        "id": "Ko-3BcFwpGZd"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for Eccentricity\n",
        "def EccentricitySolidity(img):\n",
        "    r = regionprops(img.astype(\"int8\"))\n",
        "    return r[0].eccentricity, r[0].solidity"
      ],
      "metadata": {
        "id": "NBhcUMdOpLzd"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for Skew Kurtosis\n",
        "def SkewKurtosis(img):\n",
        "    h,w = img.shape\n",
        "    x = range(w)  # cols value\n",
        "    y = range(h)  # rows value\n",
        "    #calculate projections along the x and y axes\n",
        "    xp = np.sum(img,axis=0)\n",
        "    yp = np.sum(img,axis=1)\n",
        "    #centroid\n",
        "    cx = np.sum(x*xp)/np.sum(xp)\n",
        "    cy = np.sum(y*yp)/np.sum(yp)\n",
        "    #standard deviation\n",
        "    x2 = (x-cx)**2\n",
        "    y2 = (y-cy)**2\n",
        "    sx = np.sqrt(np.sum(x2*xp)/np.sum(img))\n",
        "    sy = np.sqrt(np.sum(y2*yp)/np.sum(img))\n",
        "\n",
        "    #skewness\n",
        "    x3 = (x-cx)**3\n",
        "    y3 = (y-cy)**3\n",
        "    skewx = np.sum(xp*x3)/(np.sum(img) * sx**3)\n",
        "    skewy = np.sum(yp*y3)/(np.sum(img) * sy**3)\n",
        "\n",
        "    #Kurtosis\n",
        "    x4 = (x-cx)**4\n",
        "    y4 = (y-cy)**4\n",
        "    # 3 is subtracted to calculate relative to the normal distribution\n",
        "    kurtx = np.sum(xp*x4)/(np.sum(img) * sx**4) - 3\n",
        "    kurty = np.sum(yp*y4)/(np.sum(img) * sy**4) - 3\n",
        "\n",
        "    return (skewx , skewy), (kurtx, kurty)"
      ],
      "metadata": {
        "id": "_YwqPMI4pWIC"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for extracting features using all the above functions\n",
        "\n",
        "def getFeatures(path, img=None, display=False):\n",
        "    if img is None:\n",
        "        img = mpimg.imread(path)\n",
        "    img = preproc(path, display=display)\n",
        "    ratio = Ratio(img)\n",
        "    centroid = Centroid(img)\n",
        "    eccentricity, solidity = EccentricitySolidity(img)\n",
        "    skewness, kurtosis = SkewKurtosis(img)\n",
        "    retVal = (ratio, centroid, eccentricity, solidity, skewness, kurtosis)\n",
        "    return retVal"
      ],
      "metadata": {
        "id": "YgElR0dYpsxy"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to get the necessay features to save in CSV file\n",
        "\n",
        "def getCSVFeatures(path, img=None, display=False):\n",
        "    if img is None:\n",
        "        img = mpimg.imread(path)\n",
        "    temp = getFeatures(path, display=display)\n",
        "    features = (temp[0], temp[1][0], temp[1][1], temp[2], temp[3], temp[4][0], temp[4][1], temp[5][0], temp[5][1])\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "CdOlPvEvqCr6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to generate CSV file\n",
        "\n",
        "def makeCSV():\n",
        "    if not(os.path.exists('drive/My Drive/SignAIChallenge/Features')):\n",
        "        os.mkdir('drive/My Drive/SignAIChallenge/Features')\n",
        "        print('New folder \"Features\" created')\n",
        "    if not(os.path.exists('drive/My Drive/SignAIChallenge/Features/Training')):\n",
        "        os.mkdir('drive/My Drive/SignAIChallenge/Features/Training')\n",
        "        print('New folder \"Features/Training\" created')\n",
        "    if not(os.path.exists('drive/My Drive/SignAIChallenge/Features/Testing')):\n",
        "        os.mkdir('drive/My Drive/SignAIChallenge/Features/Testing')\n",
        "        print('New folder \"Features/Testing\" created')\n",
        "    # genuine signatures path\n",
        "    gpath = genuine_image_paths\n",
        "    # forged signatures path\n",
        "    fpath = forged_image_paths\n",
        "    for person in range(1,13):\n",
        "        per = ('00'+str(person))[-3:]\n",
        "        print('Saving features for person id-',per)\n",
        "\n",
        "        with open('drive/My Drive/SignAIChallenge/Features/Training/training_'+per+'.csv', 'w') as handle:\n",
        "            handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
        "            # Training set\n",
        "            for i in range(0,3):\n",
        "                source = os.path.join(gpath, per+per+'_00'+str(i)+'.png')\n",
        "                features = getCSVFeatures(path=source)\n",
        "                handle.write(','.join(map(str, features))+',1\\n')\n",
        "            for i in range(0,3):\n",
        "                source = os.path.join(fpath, '021'+per+'_00'+str(i)+'.png')\n",
        "                features = getCSVFeatures(path=source)\n",
        "                handle.write(','.join(map(str, features))+',0\\n')\n",
        "\n",
        "        with open('drive/My Drive/SignAIChallenge/Features/Testing/testing_'+per+'.csv', 'w') as handle:\n",
        "            handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
        "            # Testing set\n",
        "            for i in range(3, 5):\n",
        "                source = os.path.join(gpath, per+per+'_00'+str(i)+'.png')\n",
        "                features = getCSVFeatures(path=source)\n",
        "                handle.write(','.join(map(str, features))+',1\\n')\n",
        "            for i in range(3,5):\n",
        "                source = os.path.join(fpath, '021'+per+'_00'+str(i)+'.png')\n",
        "                features = getCSVFeatures(path=source)\n",
        "                handle.write(','.join(map(str, features))+',0\\n')"
      ],
      "metadata": {
        "id": "ivSQESqRqkqr"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calling the function to make CSV file\n",
        "makeCSV()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-w6cyQFtCoJ",
        "outputId": "31027376-e2e8-4268-a518-e6439c85844d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving features for person id- 001\n",
            "Saving features for person id- 002\n",
            "Saving features for person id- 003\n",
            "Saving features for person id- 004\n",
            "Saving features for person id- 005\n",
            "Saving features for person id- 006\n",
            "Saving features for person id- 007\n",
            "Saving features for person id- 008\n",
            "Saving features for person id- 009\n",
            "Saving features for person id- 010\n",
            "Saving features for person id- 011\n",
            "Saving features for person id- 012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow Model"
      ],
      "metadata": {
        "id": "0Wl3H50Ctx9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def testing(path):\n",
        "    feature = getCSVFeatures(path)\n",
        "    if not(os.path.exists('drive/My Drive/SignAIChallenge/TestFeatures')):\n",
        "        os.mkdir('drive/My Drive/SignAIChallenge/TestFeatures')\n",
        "    with open('drive/My Drive/SignAIChallenge/TestFeatures/testcsv.csv', 'w') as handle:\n",
        "        handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y\\n')\n",
        "        handle.write(','.join(map(str, feature))+'\\n')"
      ],
      "metadata": {
        "id": "-ap7QLtNtOc7"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to read data from CSV\n",
        "from tensorflow.python.framework import ops\n",
        "import tensorflow.compat.v1 as compv\n",
        "\n",
        "n_input = 9\n",
        "train_person_id = input(\"Enter person's id : \")\n",
        "check = input(\"Do you want to check for real or forged?\")\n",
        "test_image_path = input(\"Enter path of signature image : \")\n",
        "train_path = 'drive/My Drive/SignAIChallenge/Features/Training/training_'+train_person_id+'.csv'\n",
        "\n",
        "testing('drive/My Drive/SignAIChallenge/'+check+'/'+test_image_path+'.png')\n",
        "test_path = 'drive/My Drive/SignAIChallenge/TestFeatures/testcsv.csv'\n",
        "\n",
        "def readCSV(train_path, test_path, type2=False):\n",
        "    # Reading train data\n",
        "    df = pd.read_csv(train_path, usecols=range(n_input))\n",
        "    train_input = np.array(df.values)\n",
        "    train_input = train_input.astype(np.float32, copy=False)  # Converting input to float_32\n",
        "    df = pd.read_csv(train_path, usecols=(n_input,))\n",
        "    temp = [elem[0] for elem in df.values]\n",
        "    correct = np.array(temp)\n",
        "    corr_train = keras.utils.to_categorical(correct,2)      # Converting to one hot\n",
        "    # Reading test data\n",
        "    df = pd.read_csv(test_path, usecols=range(n_input))\n",
        "    test_input = np.array(df.values)\n",
        "    test_input = test_input.astype(np.float32, copy=False)\n",
        "    if not(type2):\n",
        "        df = pd.read_csv(test_path, usecols=(n_input,))\n",
        "        temp = [elem[0] for elem in df.values]\n",
        "        correct = np.array(temp)\n",
        "        corr_test = keras.utils.to_categorical(correct,2)      # Converting to one hot\n",
        "    if not(type2):\n",
        "        return train_input, corr_train, test_input, corr_test\n",
        "    else:\n",
        "        return train_input, corr_train, test_input\n",
        "\n",
        "ops.reset_default_graph()\n",
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 1000\n",
        "display_step = 1\n",
        "\n",
        "# Network Parameters\n",
        "n_hidden_1 = 7 # 1st layer number of neurons\n",
        "n_hidden_2 = 10 # 2nd layer number of neurons\n",
        "n_hidden_3 = 30 # 3rd layer\n",
        "n_classes = 2 # no. of classes (genuine or forged)\n",
        "\n",
        "# tf Graph input\n",
        "compv.disable_v2_behavior()\n",
        "#x = tf.placeholder(shape=[None, 2], dtype=tf.float32)\n",
        "X = compv.placeholder(\"float\", [None, n_input])\n",
        "Y = compv.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "# Store layers weight & bias\n",
        "weights = {\n",
        "    'h1': tf.Variable(tf.random.normal([n_input, n_hidden_1], seed=1)),\n",
        "    'h2': tf.Variable(tf.random.normal([n_hidden_1, n_hidden_2])),\n",
        "    'h3': tf.Variable(tf.random.normal([n_hidden_2, n_hidden_3])),\n",
        "    'out': tf.Variable(tf.random.normal([n_hidden_1, n_classes], seed=2))\n",
        "}\n",
        "biases = {\n",
        "    'b1': tf.Variable(tf.random.normal([n_hidden_1], seed=3)),\n",
        "    'b2': tf.Variable(tf.random.normal([n_hidden_2])),\n",
        "    'b3': tf.Variable(tf.random.normal([n_hidden_3])),\n",
        "    'out': tf.Variable(tf.random.normal([n_classes], seed=4))\n",
        "}\n",
        "\n",
        "\n",
        "# Create model\n",
        "def multilayer_perceptron(x):\n",
        "    layer_1 = tf.tanh((tf.matmul(x, weights['h1']) + biases['b1']))\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
        "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
        "    out_layer = tf.tanh(tf.matmul(layer_1, weights['out']) + biases['out'])\n",
        "    return out_layer\n",
        "\n",
        "# Construct model\n",
        "logits = multilayer_perceptron(X)\n",
        "\n",
        "# Define loss and optimizer\n",
        "loss_op = tf.reduce_mean(tf.math.squared_difference(logits, Y))\n",
        "optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# For accuracies\n",
        "pred = tf.nn.softmax(logits)  # Apply softmax to logits\n",
        "correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(Y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "def evaluate(train_path, test_path, type2=False):\n",
        "    if not(type2):\n",
        "        train_input, corr_train, test_input, corr_test = readCSV(train_path, test_path)\n",
        "    else:\n",
        "        train_input, corr_train, test_input = readCSV(train_path, test_path, type2)\n",
        "    ans = 'Random'\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "        # Training cycle\n",
        "        for epoch in range(training_epochs):\n",
        "            # Run optimization op (backprop) and cost op (to get loss value)\n",
        "            _, cost = sess.run([train_op, loss_op], feed_dict={X: train_input, Y: corr_train})\n",
        "            if cost<0.0001:\n",
        "                break\n",
        "#             # Display logs per epoch step\n",
        "#             if epoch % 999 == 0:\n",
        "#                 print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(cost))\n",
        "#         print(\"Optimization Finished!\")\n",
        "\n",
        "        # Finding accuracies\n",
        "        accuracy1 =  accuracy.eval({X: train_input, Y: corr_train})\n",
        "#         print(\"Accuracy for train:\", accuracy1)\n",
        "#         print(\"Accuracy for test:\", accuracy2)\n",
        "        if type2 is False:\n",
        "            accuracy2 =  accuracy.eval({X: test_input, Y: corr_test})\n",
        "            return accuracy1, accuracy2\n",
        "        else:\n",
        "            prediction = pred.eval({X: test_input})\n",
        "            if prediction[0][1]>prediction[0][0]:\n",
        "                print('Genuine Image')\n",
        "                return True\n",
        "            else:\n",
        "                print('Forged Image')\n",
        "                return False\n",
        "\n",
        "\n",
        "evaluate(train_path, test_path, type2=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "FZ72-tMPvvhP",
        "outputId": "d1c992d5-fcea-4706-d688-e420501da443"
      },
      "execution_count": 49,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter person's id : 001\n",
            "Do you want to check for real or forged?forged\n",
            "Enter path of signature image : 021001_003\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "_BaseOptimizer.minimize() missing 1 required positional argument: 'var_list'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-bc8c3736faa0>\u001b[0m in \u001b[0;36m<cell line: 84>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mloss_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquared_difference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;31m# For accuracies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: _BaseOptimizer.minimize() missing 1 required positional argument: 'var_list'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PHWnMGdcw159"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7j9uK7gixhb5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}